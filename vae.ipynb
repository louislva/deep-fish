{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12931f700>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fish_drawings = np.load('data/full_numpy_bitmap_fish.npy').reshape((-1, 28, 28))\n",
    "plt.imshow(fish_drawings[0], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        # input image -> encoding\n",
    "        self.conv1 = nn.Conv2d(1, 8, (3, 3), padding=(1, 1)) # 1x28x28 -> 8x14x14\n",
    "        self.conv2 = nn.Conv2d(8, 8, (3, 3), padding=(1, 1)) # 8x14x14 -> 8x7x7\n",
    "        self.conv3 = nn.Conv2d(8, 16, (3, 3), padding=(1, 1)) # 8x7x7 -> 16x3x3\n",
    "        self.conv4 = nn.Conv2d(16, 32, (3, 3), padding=(1, 1)) # 16x3x3 -> 32x1x1\n",
    "        \n",
    "        self.linear1 = nn.Linear(32, 16)\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.linear3 = nn.Linear(8, 4)\n",
    "        \n",
    "        # encoding -> probability distributions\n",
    "        self.linear_mu = nn.Linear(4, 4)\n",
    "        self.linear_log_var = nn.Linear(4, 4)\n",
    "        \n",
    "        # distribution sample -> decoded image\n",
    "        self.uplinear1 = nn.Linear(4, 8)\n",
    "        self.uplinear2 = nn.Linear(8, 16)\n",
    "        self.uplinear3 = nn.Linear(16, 32)\n",
    "        \n",
    "        self.deconv1 = nn.Conv2d(32, 16, (3, 3), padding=(2, 2)) # 1x1x32 -> 4x4x16\n",
    "        self.deconv2 = nn.Conv2d(16, 8, (3, 3), padding=(2, 2)) # 4x4x16 -> 10x10x8\n",
    "        self.deconv3 = nn.Conv2d(8, 8, (3, 3), padding=(2, 2)) # 10x10x8 -> 22x22x8\n",
    "        self.deconv4 = nn.Conv2d(8, 4, (3, 3), padding=(2, 2)) # 22x22x8 -> 24x24x4\n",
    "        self.deconv5 = nn.Conv2d(4, 4, (3, 3), padding=(2, 2)) # 24x24x4 -> 26x26x4\n",
    "        self.deconv6 = nn.Conv2d(4, 1, (3, 3), padding=(2, 2)) # 26x26x4 -> 28x28x4\n",
    "        \n",
    "        # reconstruction loss function parameters\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # make sure it's 2d, that there's one channel, and that it's encoded as batch\n",
    "        x = torch.reshape(x, (-1, 1, 28, 28))\n",
    "        \n",
    "        # reduce with conv & pool; 28x28x1 -> 1x1x32\n",
    "        x = self.conv1(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        # reduce with fully connected from 2x2x16 (64) -> 16\n",
    "        x = torch.reshape(x, (-1, 32))\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "                \n",
    "        mu = self.linear_mu(x)\n",
    "        log_var = self.linear_log_var(x)\n",
    "\n",
    "        return x, mu, log_var\n",
    "    \n",
    "    def decode(self, x):        \n",
    "        x = self.uplinear1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.uplinear2(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.uplinear3(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = torch.reshape(x, (-1, 32, 1, 1))\n",
    "        \n",
    "        x = nn.Upsample(scale_factor=2)(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "           \n",
    "        x = nn.Upsample(scale_factor=2)(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = nn.Upsample(scale_factor=2)(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.deconv4(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.deconv5(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.deconv6(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        return x.reshape((-1, 28, 28))\n",
    "        \n",
    "vae = VariationalAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/8384\n",
      "Loss: tensor(4311.0454, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ec6763b07ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfish_drawings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-ec6763b07ab2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_var\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8c2aaa56e5c7>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 415\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def normal_probability(mean, scale, sample):\n",
    "    normal_dist = torch.distributions.normal.Normal(mean, scale, validate_args=True)\n",
    "    log_prob = normal_dist.log_prob(sample + 0.1)\n",
    "    \n",
    "    return torch.sum(log_prob, dim=(2, 1))\n",
    "\n",
    "def kl_divergence(mu, var, z):\n",
    "    # for z, how much less likely is it that it came from mu = 0 and var = 1 than the current mu and var?\n",
    "    p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(var))\n",
    "    q = torch.distributions.Normal(mu, var)\n",
    "    \n",
    "    log_prob_qz = q.log_prob(z)\n",
    "    log_prob_pz = p.log_prob(z)\n",
    "    \n",
    "    kl = log_prob_qz - log_prob_pz\n",
    "    kl = kl.sum(-1)\n",
    "    return kl\n",
    "    \n",
    "\n",
    "def train(model, data):\n",
    "    epoch_count = 8\n",
    "    batch_size = 16\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "    for epoch_index in range(epoch_count):\n",
    "        batch_count = len(data) // batch_size\n",
    "\n",
    "        \n",
    "        for batch_index in range(batch_count):\n",
    "            batch = data[np.random.randint(0, len(data) - 1, (batch_size,))]\n",
    "            x = torch.from_numpy(batch).float()\n",
    "            \n",
    "            _, mu, log_var = vae.encode(x)\n",
    "            var = torch.exp(log_var / 2)\n",
    "            \n",
    "            # create q distribution from our mean and variance that come from a learned relation to encoding\n",
    "            q = torch.distributions.Normal(mu, var)\n",
    "            z = q.rsample()\n",
    "            \n",
    "            # now decode our distribution sample, z; this should reconstruct the x, so this is x hat\n",
    "            x_ = vae.decode(z)\n",
    "            \n",
    "            # probability of x given x_; found by calculating x pixel probability given x_ as mean and exp(vae.log_scale) as variance\n",
    "            reconstruction_loss = normal_probability(x_, torch.exp(vae.log_scale), x) \n",
    "            \n",
    "            # q should approach Normal(0, 1)\n",
    "            kl_divergence_loss = kl_divergence(mu, var, z)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            loss = (kl_divergence_loss - reconstruction_loss).mean()\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(str(batch_index) + '/' + str(batch_count))\n",
    "            print('Loss:', loss)\n",
    "    \n",
    "train(vae, fish_drawings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagine(model, z):     \n",
    "    y = vae.decode(z).reshape((-1, 28, 28))\n",
    "       \n",
    "    plt.imshow(y.detach().numpy().reshape((28,28)), interpolation='nearest')\n",
    "    \n",
    "def random_imagination(model):     \n",
    "    q = torch.distributions.Normal(torch.zeros((1, 4)), torch.ones((1, 4)))\n",
    "    z = q.sample()\n",
    "\n",
    "    imagine(model, z)\n",
    "    \n",
    "random_imagination(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def imagine_with_sliders(a,b,c,d):\n",
    "    print(a,b,c,d)\n",
    "    imagine(vae, torch.tensor([a,b,c,d]).float())\n",
    "    \n",
    "interact(\n",
    "    imagine_with_sliders,\n",
    "    a=FloatSlider(min=-2, max=2, step=0.25),\n",
    "    b=FloatSlider(min=-2, max=2, step=0.25),\n",
    "    c=FloatSlider(min=-2, max=2, step=0.25),\n",
    "    d=FloatSlider(min=-2, max=2, step=0.25)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# got this from: https://github.com/kkroening/ffmpeg-python/issues/246#issuecomment-520200981 🙏\n",
    "def vidwrite(filename, images, framerate=60, vcodec='libx264'):\n",
    "    if not isinstance(images, np.ndarray):\n",
    "        images = np.asarray(images)\n",
    "    n,height,width,channels = images.shape\n",
    "    process = (\n",
    "        ffmpeg\n",
    "            .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height))\n",
    "            .output(filename, pix_fmt='yuv420p', vcodec=vcodec, r=framerate)\n",
    "            .overwrite_output()\n",
    "            .run_async(pipe_stdin=True)\n",
    "    )\n",
    "    for frame in images:\n",
    "        process.stdin.write(\n",
    "            frame\n",
    "                .astype(np.uint8)\n",
    "                .tobytes()\n",
    "        )\n",
    "    process.stdin.close()\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# make a little wiggling, swimming fish\n",
    "from time import sleep\n",
    "\n",
    "def render_animation():\n",
    "    start = np.array([2, -0.5, 2, -0.5])\n",
    "    end = np.array([2, -0.5, 1.5, 1])\n",
    "    \n",
    "    length = 16\n",
    "    \n",
    "    zs = []\n",
    "    \n",
    "    for t in range(length):\n",
    "        progress = (t / (length - 1))\n",
    "        weighted_start = start * (1 - progress)\n",
    "        weighted_end = end * progress\n",
    "        \n",
    "        zs.append(weighted_start + weighted_end)\n",
    "    \n",
    "    ys = []\n",
    "    \n",
    "    for z in zs:\n",
    "        ys.append(vae.decode(torch.from_numpy(z).float()).reshape((28, 28)).detach().numpy())\n",
    "    \n",
    "    return ys\n",
    "\n",
    "\n",
    "frames = np.array(render_animation())\n",
    "\n",
    "frames = np.stack([frames,frames,frames], axis=3, out=None) # give it 3 channels\n",
    "frames = np.concatenate([frames, np.flip(frames, axis=0)], axis=0) # make it go back and forward\n",
    "frames = np.concatenate([frames for _ in range(10)], axis=0)\n",
    "\n",
    "vidwrite('./vid.mp4', frames, framerate=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    torch.save(vae.state_dict(), './vae_state_dict')\n",
    "    \n",
    "#save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    vae.load_state_dict(torch.load('./vae_state_dict'))\n",
    "    \n",
    "load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
