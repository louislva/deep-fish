{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1302fae50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fish_drawings = np.load('data/full_numpy_bitmap_fish.npy').reshape((-1, 28, 28))\n",
    "plt.imshow(fish_drawings[0], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        # input image -> encoding\n",
    "        self.conv1 = nn.Conv2d(1, 8, (3, 3), padding=(1, 1)) # 1x28x28 -> 8x14x14\n",
    "        self.conv2 = nn.Conv2d(8, 8, (3, 3), padding=(1, 1)) # 8x14x14 -> 8x7x7\n",
    "        self.conv3 = nn.Conv2d(8, 16, (3, 3), padding=(1, 1)) # 8x7x7 -> 16x3x3\n",
    "        self.conv4 = nn.Conv2d(16, 32, (3, 3), padding=(1, 1)) # 16x3x3 -> 32x1x1\n",
    "        \n",
    "        self.linear1 = nn.Linear(32, 16)\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.linear3 = nn.Linear(8, 4)\n",
    "        \n",
    "        # encoding -> probability distributions\n",
    "        self.linear_mu = nn.Linear(4, 4)\n",
    "        self.linear_log_var = nn.Linear(4, 4)\n",
    "        \n",
    "        # distribution sample -> decoded image\n",
    "        self.uplinear1 = nn.Linear(4, 8)\n",
    "        self.uplinear2 = nn.Linear(8, 16)\n",
    "        self.uplinear3 = nn.Linear(16, 32)\n",
    "        \n",
    "        self.deconv1 = nn.Conv2d(32, 16, (3, 3), padding=(2, 2)) # 1x1x32 -> 4x4x16\n",
    "        self.deconv2 = nn.Conv2d(16, 8, (3, 3), padding=(2, 2)) # 4x4x16 -> 10x10x8\n",
    "        self.deconv3 = nn.Conv2d(8, 8, (3, 3), padding=(2, 2)) # 10x10x8 -> 22x22x8\n",
    "        self.deconv4 = nn.Conv2d(8, 4, (3, 3), padding=(2, 2)) # 22x22x8 -> 24x24x4\n",
    "        self.deconv5 = nn.Conv2d(4, 4, (3, 3), padding=(2, 2)) # 24x24x4 -> 26x26x4\n",
    "        self.deconv6 = nn.Conv2d(4, 1, (3, 3), padding=(2, 2)) # 26x26x4 -> 28x28x4\n",
    "        \n",
    "        # reconstruction loss function parameters\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # make sure it's 2d, that there's one channel, and that it's encoded as batch\n",
    "        x = torch.reshape(x, (-1, 1, 28, 28))\n",
    "        \n",
    "        # reduce with conv & pool; 28x28x1 -> 1x1x32\n",
    "        x = self.conv1(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = nn.MaxPool2d((2, 2))(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        # reduce with fully connected from 2x2x16 (64) -> 16\n",
    "        x = torch.reshape(x, (-1, 32))\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.linear3(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "                \n",
    "        mu = self.linear_mu(x)\n",
    "        log_var = self.linear_log_var(x)\n",
    "\n",
    "        return x, mu, log_var\n",
    "    \n",
    "    def decode(self, x):        \n",
    "        x = self.uplinear1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.uplinear2(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.uplinear3(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = torch.reshape(x, (-1, 32, 1, 1))\n",
    "        \n",
    "        x = nn.Upsample(scale_factor=2)(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "           \n",
    "        x = nn.Upsample(scale_factor=2)(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = nn.Upsample(scale_factor=2)(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.deconv4(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.deconv5(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        x = self.deconv6(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        \n",
    "        return x.reshape((-1, 28, 28))\n",
    "        \n",
    "vae = VariationalAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-031dfd0ef8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reconstruction loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfish_drawings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-173-031dfd0ef8c4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def normal_probability(mean, scale, sample):\n",
    "    normal_dist = torch.distributions.normal.Normal(mean, scale, validate_args=True)\n",
    "    log_prob = normal_dist.log_prob(sample + 0.1)\n",
    "    \n",
    "    return torch.sum(log_prob, dim=(2, 1))\n",
    "\n",
    "def kl_divergence(mu, var, z):\n",
    "    # for z, how much less likely is it that it came from mu = 0 and var = 1 than the current mu and var?\n",
    "    p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(var))\n",
    "    q = torch.distributions.Normal(mu, var)\n",
    "    \n",
    "    log_prob_qz = q.log_prob(z)\n",
    "    log_prob_pz = p.log_prob(z)\n",
    "    \n",
    "    kl = log_prob_qz - log_prob_pz\n",
    "    kl = kl.sum(-1)\n",
    "    return kl\n",
    "    \n",
    "\n",
    "def train(model, data):\n",
    "    epoch_count = 8\n",
    "    batch_size = 16\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "    for epoch_index in range(epoch_count):\n",
    "        batch_count = len(data) // batch_size\n",
    "\n",
    "        \n",
    "        for batch_index in range(batch_count):\n",
    "            batch = data[np.random.randint(0, len(data) - 1, (batch_size,))]\n",
    "            x = torch.from_numpy(batch).float() / 255\n",
    "            \n",
    "            _, mu, log_var = vae.encode(x)\n",
    "            var = torch.exp(log_var / 2)\n",
    "            \n",
    "            # create q distribution from our mean and variance that come from a learned relation to encoding\n",
    "            q = torch.distributions.Normal(mu, var)\n",
    "            z = q.rsample()\n",
    "            \n",
    "            # now decode our distribution sample, z; this should reconstruct the x, so this is x hat\n",
    "            x_ = vae.decode(z)\n",
    "            \n",
    "            # probability of x given x_; found by calculating x pixel probability given x_ as mean and exp(vae.log_scale) as variance\n",
    "            reconstruction_loss = normal_probability(x_, torch.exp(vae.log_scale), x) \n",
    "            \n",
    "            # q should approach Normal(0, 1)\n",
    "            kl_divergence_loss = kl_divergence(mu, var, z)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            beta = 0.1 # lower will result in better reconstruction but worse latent space\n",
    "            loss = ((kl_divergence_loss * beta) - reconstruction_loss).mean()\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(str(batch_index) + '/' + str(batch_count))\n",
    "            print('KL Divergence  loss:', kl_divergence_loss.mean())\n",
    "            print('Reconstruction loss:', -reconstruction_loss.mean())\n",
    "    \n",
    "train(vae, fish_drawings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imagine(model, z):     \n",
    "    y = vae.decode(z).reshape((-1, 28, 28))\n",
    "       \n",
    "    plt.imshow(y.detach().numpy().reshape((28,28)), interpolation='nearest')\n",
    "    \n",
    "def random_imagination(model):     \n",
    "    q = torch.distributions.Normal(torch.zeros((1, 4)), torch.ones((1, 4)))\n",
    "    z = q.sample()\n",
    "\n",
    "    imagine(model, z)\n",
    "    \n",
    "random_imagination(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945ec931733f4ef2b1be241b53fb6fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='a', max=2.0, min=-2.0, step=0.25), FloatSlider(value‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.imagine_with_sliders(a, b, c, d)>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def imagine_with_sliders(a,b,c,d):\n",
    "    print(a,b,c,d)\n",
    "    imagine(vae, torch.tensor([a,b,c,d]).float())\n",
    "    \n",
    "interact(\n",
    "    imagine_with_sliders,\n",
    "    a=FloatSlider(min=-2, max=2, step=0.25),\n",
    "    b=FloatSlider(min=-2, max=2, step=0.25),\n",
    "    c=FloatSlider(min=-2, max=2, step=0.25),\n",
    "    d=FloatSlider(min=-2, max=2, step=0.25)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# got this from: https://github.com/kkroening/ffmpeg-python/issues/246#issuecomment-520200981 üôè\n",
    "def vidwrite(filename, images, framerate=60, vcodec='libx264'):\n",
    "    if not isinstance(images, np.ndarray):\n",
    "        images = np.asarray(images)\n",
    "    n,height,width,channels = images.shape\n",
    "    process = (\n",
    "        ffmpeg\n",
    "            .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height))\n",
    "            .output(filename, pix_fmt='yuv420p', vcodec=vcodec, r=framerate)\n",
    "            .overwrite_output()\n",
    "            .run_async(pipe_stdin=True)\n",
    "    )\n",
    "    for frame in images:\n",
    "        process.stdin.write(\n",
    "            frame\n",
    "                .astype(np.uint8)\n",
    "                .tobytes()\n",
    "        )\n",
    "    process.stdin.close()\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a little wiggling, swimming fish\n",
    "from time import sleep\n",
    "\n",
    "def render_animation():\n",
    "    start = np.array([2, -0.5, 2, -0.5])\n",
    "    end = np.array([2, -0.5, 1.5, 1])\n",
    "    \n",
    "    length = 16\n",
    "    \n",
    "    zs = []\n",
    "    \n",
    "    for t in range(length):\n",
    "        progress = (t / (length - 1))\n",
    "        weighted_start = start * (1 - progress)\n",
    "        weighted_end = end * progress\n",
    "        \n",
    "        zs.append(weighted_start + weighted_end)\n",
    "    \n",
    "    ys = []\n",
    "    \n",
    "    for z in zs:\n",
    "        ys.append(vae.decode(torch.from_numpy(z).float()).reshape((28, 28)).detach().numpy())\n",
    "    \n",
    "    return ys\n",
    "\n",
    "\n",
    "frames = np.array(render_animation())\n",
    "\n",
    "frames = np.stack([frames,frames,frames], axis=3, out=None) # give it 3 channels\n",
    "frames = np.concatenate([frames, np.flip(frames, axis=0)], axis=0) # make it go back and forward\n",
    "frames = np.concatenate([frames for _ in range(10)], axis=0)\n",
    "\n",
    "vidwrite('./vid.mp4', frames, framerate=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    torch.save(vae.state_dict(), './vae_state_dict')\n",
    "    \n",
    "#save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    vae.load_state_dict(torch.load('./vae_state_dict'))\n",
    "    \n",
    "load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
